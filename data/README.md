* mongoimport --db test --collection tweets_collection --file tweets_collection.json

* db.all_tweets.ensureIndex({ t: "text" })

* Make sure you drop the collection first.
* Use upload.sh to upload data.
```
cd data/Tagged/
sh ../upload.sh
cd ../Untagged/
sh ../upload.sh
```

* Ensure index
```
use twitter
db.tweets_collection.ensureIndex({ t: "text" })
exit
```

290726 tweets unlocated, total 
* Dumping data from mongo: `mongodump --db test --collection tweets_collection -o /home/kaustubh/`

Data stored in .bson format in ~/test/

* Convert bson to json: `bsondump tweets_collection.bson > tweets_collection.json `


Stats: 

40,524 tweets. 14299 untagged. 

Tweets from 2017-09-12 04:05:05.000Z to 2017-10-13 07:20:43.000Z

Min date query:
```sh
db.getCollection('tweets_collection').aggregate(
   [
     {
       $group:
       {
         _id: {},
         minDate: { $min: "$cr" }
       }
     }
   ]
  );
```

## Analysis to do:

*  Day wise analysis: Flood #, Dengue #, min, max, average
	count_tweets.py for untagged and tagged separately.
	`python ../count_tweets.py` in folders

 * Containing both words: `db.getCollection('all_tweets').find({$text: {$search: "\"flood\" \"dengue\""} }).count()`
 * Containing flood, not dengue: `db.getCollection('all_tweets').find({$text: {$search: "flood -dengue"}}).count()`
 * Containing flood / dengue: `db.getCollection('all_tweets').find({$text: {$search: "flood,dengue"} }).count()` 265688

* Locations mentioned, frequency, floods, dengue separately [Done together for now]
 * Locations: `db.getCollection('all_tweets').distinct('loc')` 962

```py
# Redundant
db.all_tweets.aggregate([
    {
        $match: {
            loc: { $not: {$size: 0} }
        }
    },
    { $unwind: "$loc" },
    {
        $group: {
            _id: {$toLower: '$loc'},
            count: { $sum: 1 }
        }
    },
    {
        $match: {
            count: { $gte: 1 }
        }
    },
    { $sort : { count : -1} },
    { $limit : 100 }
]);
```

 /*might need to copy paste from mongo shell, not robo3t*/ Saved in location_counts.json. Run location_tabs.py
```
db.all_tweets.aggregate(
   {$group : { _id : '$loc', count : {$sum : 1}}}
)
```

* locations frequency 'wordcloud', urban rural, state, state, heatmap.

* All tagged. Generated by us, and actual geotagged.
Actual geotagged : 1099
 * `db.getCollection('all_tweets').find({"f": {$eq: "1e222211"} }).count()` => assigned location
 * `db.getCollection('all_tweets').find({"f": {$nin: [ "1e222211", ""] } }).count()` => Actual geotagged

* % of tweets identified, test case 1000 manually checked. => how many mistaken, 

* why untagged. Should have been tagged. 

* Improve ? Stemming.

* w2v for locations ?

* Improve coverage ? P, R, F, Roc, Auc, ?


** Retweets ?

** Remove en languages - spanish, etc.